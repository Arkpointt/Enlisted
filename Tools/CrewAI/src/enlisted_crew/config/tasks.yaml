# Enlisted CrewAI Task Definitions
# Supports feature development, content creation, and validation workflows

# =============================================================================
# RESEARCH & ANALYSIS TASKS
# =============================================================================

analyze_systems:
  description: >
    Research and analyze how Enlisted systems integrate for a feature:
    
    Feature: {feature_name}
    Related Systems: {related_systems}
    
    WORKFLOW:
    1. Call load_domain_context_tool FIRST to get current game system values
    2. Search documentation to find relevant specs and design docs
    3. Search codebase for relevant C# files
    4. Trace data flows between systems
    
    SEARCH EFFICIENCY (saves tokens and time):
    - All search results are cached; avoid re-searching the same query
    - Limit to 3-5 distinct queries; when you have enough info, stop and summarize
    - Focus on system integration, not exhaustive code reading
    
    ANALYSIS TASKS:
    1. Identify relevant C# files and their responsibilities
    2. Trace data flows between systems (Orchestrator, Managers, Content)
    3. Find integration points where new code would connect
    4. Identify existing patterns to follow
    5. Note any constraints (save/load, performance, mod compatibility)
  expected_output: >
    Systems analysis report with:
    - List of relevant files with their responsibilities
    - Data flow diagram (text-based)
    - Integration points for new feature
    - Existing patterns to follow
    - Constraints and considerations
  agent: systems_analyst

analyze_codebase:
  description: >
    Analyze existing C# implementation to understand patterns:
    
    Focus: {focus_area}
    Files: {file_paths}
    
    WORKFLOW:
    1. Call load_code_context_tool FIRST to load dev guide, APIs, common issues
    2. Use search_csharp_tool to find relevant files
    3. Use read_csharp_snippet_tool for targeted sections (prefer over full file reads)
    4. Only use read_csharp_tool when you need full file context
    
    SEARCH EFFICIENCY:
    - Track files you've already found; don't re-search
    - Limit total searches to 5-8 per task
    - When you have enough info, STOP and summarize
    
    ANALYSIS TASKS:
    1. Read and understand the existing code
    2. Identify patterns (data models, method signatures, error handling)
    3. Find save/load handling (SyncData implementations)
    4. Note any Harmony patches that might conflict
    5. Check for existing tests or validation
  expected_output: >
    Code analysis report with:
    - Summary of existing implementation
    - Key patterns identified
    - Save/load considerations
    - Potential conflicts or dependencies
    - Recommendations for integration
  agent: code_analyst

analyze_content_structure:
  description: >
    Analyze JSON content structure and delivery pipeline:
    
    Content Type: {content_type}
    Files: {file_paths}
    
    Tasks:
    1. Review JSON structure and schema compliance
    2. Trace content ID through C# delivery system
    3. Identify how requirements/triggers are processed
    4. Note any gaps in content coverage
    5. Check localization completeness
  expected_output: >
    Content analysis report with:
    - Schema compliance status
    - Delivery pipeline (JSON â†’ C# â†’ UI)
    - Content gaps identified
    - Localization status
    - Integration recommendations
  agent: content_analyst

investigate_bug:
  description: >
    Investigate a bug or crash reported by the user:
    
    Bug Description: {bug_description}
    Error Codes: {error_codes}
    Reproduction Steps: {repro_steps}
    
    INVESTIGATION PROCESS:
    1. Search mod debug logs for error codes (E-*, W-*) and stack traces
    2. Check Conflicts-A_*.log for Harmony patch conflicts with other mods
    3. Check native crash logs if game hard-crashed (no error codes visible)
    4. Identify the failing method from stack trace
    5. Read the relevant C# source files
    6. Trace the bug to root cause
    7. Check for related patterns that might have same issue
    8. Propose fix with minimal code changes
    
    ERROR CODE MEANINGS:
    - E-ENCOUNTER-* = Battle/menu state issues (PlayerEncounter, MapEvent)
    - E-SAVELOAD-* = Save corruption or data migration failures
    - E-QM-* = Quartermaster UI issues
    - E-CAMPUI-* = Camp menu display failures
    - E-CONTENT-* = JSON content loading/processing errors
    - W-DLC-* = Missing Naval/WarSails DLC (NOT a bug - expected gating)
    - W-REFLECT-* = Native API changed between Bannerlord versions
    
    LOG LOCATIONS (check in order):
    
    1. MOD SESSION LOG (primary - has E-*/W-* codes):
       - <bannerlord>/Modules/Enlisted/Debugging/Session-A_*.log (newest)
       - Session-B/C for previous sessions
       - Exceptions include full stack traces (de-duplicated)
    
    2. MOD CONFLICT LOG (for mod compatibility issues):
       - <bannerlord>/Modules/Enlisted/Debugging/Conflicts-A_*.log
       - Shows Harmony patch conflicts, module health, catalog status
    
    3. NATIVE CRASH LOGS (for hard game crashes):
       - C:\ProgramData\Mount and Blade II Bannerlord\logs\crashlist.txt
       - C:\ProgramData\Mount and Blade II Bannerlord\logs\CrashUploader.*.txt
       - rgl_log.txt in game directory (engine errors)
    
    DEBUG TOOLS (for reproduction):
    - settings.json: "EnableDebugTools": true enables in-game debug menu
    - Debug menu includes: force events, clear cooldowns, trigger muster, give XP
  expected_output: >
    Bug investigation report with:
    - Error codes found and their meaning
    - Stack trace analysis (from mod logs AND/OR native crash logs)
    - Harmony conflict status (if relevant)
    - Root cause identification
    - Affected files and line numbers
    - Proposed fix (code diff or description)
    - Related code that may need similar fixes
    - Confidence level (certain/likely/speculative)
    - Reproduction steps verified
  agent: code_analyst

analyze_bug_systems:
  description: >
    Analyze systems related to the bug found in the previous investigation.
    
    You will receive the bug investigation results from the prior task's context.
    
    Tasks:
    1. Review the systems identified in the bug investigation
    2. Check for related code patterns that might have similar issues
    3. Identify integration points that could be affected
    4. Assess if this is a localized bug or systemic issue
    5. Determine what other files might need similar fixes
  expected_output: >
    Systems analysis for bug with:
    - Related systems and their roles
    - Similar code patterns found
    - Scope of the issue (localized vs systemic)
    - List of files that may need fixes
    - Risk assessment for the fix
  agent: systems_analyst

propose_bug_fix:
  description: >
    Propose a minimal code fix based on the bug investigation and systems
    analysis from prior tasks (provided in context).
    
    Requirements:
    1. Propose the MINIMAL fix that addresses the root cause
    2. Follow Enlisted code style (Allman braces, _camelCase, XML docs)
    3. Use proper Bannerlord patterns
    4. Consider save/load compatibility
    5. Add appropriate error handling
    6. Include code diff or pseudocode for the fix
  expected_output: >
    Bug fix proposal with:
    - Files to modify
    - Code changes (diff format preferred)
    - Explanation of why this fixes the bug
    - Any risks or side effects
    - Testing recommendations
  agent: csharp_implementer

validate_bug_fix:
  description: >
    Validate the proposed bug fix from the prior task (provided in context).
    
    Checks:
    1. Run dotnet build to verify compilation
    2. Check code style compliance
    3. Verify the fix matches the investigation findings
    4. Assess if the fix could introduce regressions
    5. Confirm fix is minimal and targeted
  expected_output: >
    Bug fix validation report with:
    - Build status (pass/fail)
    - Style compliance
    - Fix completeness assessment
    - Regression risk assessment
    - Approval or required changes
  agent: qa_agent

# =============================================================================
# ADVISORY TASKS
# =============================================================================

suggest_improvements:
  description: >
    Analyze a system or feature area and suggest improvements:
    
    Focus Area: {focus_area}
    Current Pain Points: {pain_points}
    
    WORKFLOW:
    1. Call load_domain_context_tool FIRST to understand game systems
    2. Call load_feature_context_tool to understand architecture patterns
    3. Search docs for related design decisions and constraints
    4. Search codebase to understand current implementation
    
    ANALYSIS PROCESS:
    1. Research the current implementation thoroughly
    2. Understand WHY it was built this way (constraints, history)
    3. Identify gaps compared to industry best practices
    4. Consider Bannerlord modding constraints
    5. Propose concrete, actionable improvements
    
    SUGGESTION CATEGORIES:
    - QUICK WINS: Can implement in <1 day, low risk, high value
    - TECHNICAL DEBT: Problems that will get worse if ignored
    - FEATURE GAPS: Functionality players expect but is missing
    - ARCHITECTURE: Structural improvements for maintainability
    - FUTURE-PROOFING: Enable future features without breaking changes
    
    FOR EACH SUGGESTION INCLUDE:
    - Problem: What's wrong or missing?
    - Impact: How does this affect players/developers?
    - Solution: Concrete implementation approach
    - Effort: Hours/days estimate
    - Risk: Save compatibility, crash risk, complexity
    - Dependencies: What must exist first?
    
    CONSTRAINTS TO RESPECT:
    - .NET Framework 4.7.2 compatibility
    - Save/load compatibility with existing saves
    - Harmony patching limitations
    - Single-threaded game loop
  expected_output: >
    Architecture improvement report with:
    - Current State Assessment (brief)
    - Prioritized Suggestions by category
    - For each: Problem, Impact, Solution, Effort, Risk
    - Recommended implementation order
    - Dependencies between suggestions
  agent: architecture_advisor

review_architecture:
  description: >
    Review an existing system's architecture for quality and suggest refactoring:
    
    System: {system_name}
    Files: {file_paths}
    
    REVIEW CRITERIA:
    1. Single Responsibility: Does each class do one thing?
    2. Coupling: Are dependencies explicit and minimal?
    3. Testability: Could this be unit tested (in theory)?
    4. Error Handling: Are failures handled gracefully?
    5. Performance: Any obvious bottlenecks?
    6. Maintainability: Can a new developer understand this?
    7. Extensibility: Can new features be added without major changes?
    
    BANNERLORD-SPECIFIC CHECKS:
    - SaveableTypeDefiner: All persistent classes registered?
    - CampaignBehavior lifecycle: Proper initialization/cleanup?
    - Harmony patches: Minimal and well-guarded?
    - Native API usage: Null-safe and version-aware?
  expected_output: >
    Architecture review with:
    - Quality scores (1-5) for each criterion
    - Specific issues found
    - Refactoring suggestions with effort estimates
    - Priority ranking
  agent: architecture_advisor

# =============================================================================
# FEATURE DESIGN TASKS
# =============================================================================

design_feature:
  description: >
    Design technical specification for a new feature:
    
    Feature: {feature_name}
    Description: {description}
    Related Docs: {related_docs}
    
    WORKFLOW:
    1. Call load_feature_context_tool FIRST to load BLUEPRINT, patterns, integration
    2. Search documentation for related specs and existing designs
    3. Search codebase for similar implementations to follow
    4. Use verify_file_exists_tool before referencing any C# files
    
    SEARCH EFFICIENCY:
    - Use what other agents already found from context
    - Limit new searches to ~5 distinct queries
    - When you have enough context, STOP and produce the spec
    
    TIER-AWARE DESIGN (required for player-facing features):
    - Check knowledge/game-design-principles.md for tier guidance
    - T1-T4 (Grunt): Things happen TO the player
    - T5-T6 (NCO): Player handles their squad
    - T7+ (Commander): Player commands troops
    - Same event should have different player verbs per tier
    
    PLAYER EXPERIENCE CHECK (required):
    - What's the most memorable moment this feature creates?
    - Would a player tell a friend about this?
    - Is there player agency during crisis states?
    - Are positive outcomes as impactful as negative consequences?
    
    SPEC REQUIREMENTS:
    1. Create data models with field types and purposes
    2. Define method signatures with parameters and returns
    3. List all files that need changes (C#, JSON, docs)
    4. Design integration with existing systems
    5. Plan save/load handling
    6. Consider error handling and edge cases
    7. Create phased implementation plan
    
    Reference: ORCHESTRATOR-OPPORTUNITY-UNIFICATION.md for spec format
  expected_output: >
    Technical specification document with:
    - Problem statement and goals
    - Data model definitions (C# classes)
    - Method signatures with XML doc comments
    - File change list (create/modify)
    - Integration points with existing systems
    - Save/load considerations
    - Error handling plan
    - Phased implementation roadmap
    - Tier-aware player experience notes
  agent: feature_architect

review_feature_design:
  description: >
    Review a feature design for completeness and correctness:
    
    Specification: {spec_content}
    
    Review criteria:
    1. Does design follow Enlisted patterns?
    2. Are all integration points identified?
    3. Is save/load handling complete?
    4. Are error cases covered?
    5. Is the implementation plan realistic?
    6. Are there balance concerns?
  expected_output: >
    Design review report with:
    - Pattern compliance assessment
    - Missing integration points
    - Save/load concerns
    - Error handling gaps
    - Implementation feasibility
    - Balance recommendations
    - Approval or required changes
  agent: balance_analyst

# =============================================================================
# IMPLEMENTATION TASKS
# =============================================================================

implement_csharp:
  description: >
    Implement C# code according to specification:
    
    Specification: {spec_content}
    Files to create/modify: {file_list}
    
    WORKFLOW:
    1. Call load_code_context_tool FIRST to load dev guide, APIs, common issues
    2. Use search_native_api_tool for unfamiliar Bannerlord APIs
    3. Use verify_file_exists_tool to confirm file paths before proposing changes
    4. Use search_csharp_tool to find related code to follow as patterns
    5. Use read_csharp_snippet_tool for targeted reading (prefer over full files)
    
    CODE REQUIREMENTS:
    1. Follow Enlisted code style (Allman braces, _camelCase, XML docs)
    2. Add new files to Enlisted.csproj
    3. Use proper Bannerlord patterns (TextObject, GiveGoldAction, etc.)
    4. Implement SyncData for saveable state
    5. Add appropriate logging with ModLogger
    6. Handle null checks and edge cases
    7. Ensure .NET Framework 4.7.2 compatibility
  expected_output: >
    Implementation report with:
    - Code created/modified (file paths)
    - Patterns followed
    - Save/load implementation
    - Build status
    - Any deviations from spec with justification
  agent: csharp_implementer

implement_content:
  description: >
    Create JSON content according to specification:
    
    Content Type: {content_type}
    Requirements: {requirements}
    
    WORKFLOW:
    1. Call load_content_context_tool FIRST to load style guide, schemas, reminders
    2. Call load_domain_context_tool to understand current balance values
    3. Use list_json_event_ids_tool to check existing IDs and avoid conflicts
    4. Use read_event_file_tool to see existing examples as templates
    
    TIER-AWARE CONTENT (required):
    - Check knowledge/game-design-principles.md for tier guidance
    - T1-T4: Events happen TO the player (witness, report, participate)
    - T5-T6: Player has authority (investigate, mentor, discipline)
    - T7+: Player commands (order, allocate, petition)
    - Use soldier-eye view: "Thin gruel for dinner" not "Supply level: 35%"
    
    SCHEMA REQUIREMENTS:
    1. Follow event-system-schemas.md exactly
    2. Use proper field ordering (fallback after ID)
    3. Include all required fields (tooltips, effects)
    4. Follow writing-style-guide.md for narrative text
    5. Use thematic skill aliases where appropriate
    6. Ensure balanced effects (reference systems-integration-analysis.md)
  expected_output: >
    Content implementation report with:
    - JSON files created/modified
    - Schema validation status
    - Style compliance status
    - Balance assessment
    - Localization strings needed
  agent: content_author

# =============================================================================
# VALIDATION TASKS
# =============================================================================

validate_all:
  description: >
    Run comprehensive validation on all project content:
    1. Execute validate_content.py to check all JSON files
    2. Run sync_event_strings.py to verify localization
    3. Run dotnet build to check C# compilation
    4. Check code style compliance
    
    Report all errors with severity and file locations.
  expected_output: >
    A structured validation report listing:
    - JSON validation errors (file, line, issue)
    - Missing localization strings
    - Build errors or warnings
    - Code style issues
    - Overall pass/fail status
  agent: qa_agent

validate_implementation:
  description: >
    Validate a feature implementation against its specification:
    
    Specification: {spec_content}
    Implementation files: {file_list}
    
    Checks:
    1. All files in spec were created/modified
    2. Code follows spec's data models and methods
    3. Build succeeds with no errors
    4. Content validates with no errors
    5. Localization is complete
    6. Code style is compliant
  expected_output: >
    Implementation validation report with:
    - Spec compliance checklist
    - Build status
    - Content validation status
    - Localization status
    - Style compliance
    - Issues to fix before merge
  agent: qa_agent

validate_content_file:
  description: >
    Validate a specific content file against schema and style:
    
    File: {file_path}
    
    Checks:
    - Schema compliance (field ordering, required fields)
    - Option count rules (2-4, never 1)
    - Tooltip presence and length (<80 chars)
    - Writing style compliance
    - Skill names and effect values
  expected_output: >
    Detailed validation report with:
    - Schema violations
    - Style violations
    - Balance concerns
    - Suggested fixes
    - Pass/fail determination
  agent: content_analyst

# =============================================================================
# REVIEW TASKS
# =============================================================================

review_code:
  description: >
    Review C# code changes for Enlisted-specific issues:
    
    Files: {file_paths}
    
    Focus areas:
    - SaveableTypeDefiner registration
    - TextObject localization patterns
    - Hero/settlement null safety
    - Equipment iteration patterns
    - Gold/reputation change APIs
    - Allman braces, _camelCase naming
  expected_output: >
    Code review report with:
    - Critical issues (will cause crashes/save breaks)
    - Warnings (potential problems)
    - Style issues
    - Pattern compliance
    - Approval or required fixes
  agent: code_analyst

review_balance:
  description: >
    Review content for game balance:
    
    Target: {target}
    
    WORKFLOW:
    1. Call load_domain_context_tool FIRST to get current balance values
    2. Read the content file(s) using read_event_file_tool
    3. Compare effects against tier-appropriate ranges from knowledge files
    
    NUMERICAL BALANCE CHECKS:
    - Skill XP rewards match tier and difficulty
    - Gold amounts appropriate for tier
    - Reputation effects create meaningful tradeoffs
    - Company needs effects are proportional
    - Order events include skillXp
    
    PLAYER ENGAGEMENT CHECKS (see knowledge/game-design-principles.md):
    - Invisible effects (+1/day) need visible narrative wrappers
    - Death spirals need hero opportunity escape valves
    - Positive arcs should feel as impactful as negative spirals
    - Events need tier-appropriate player agency
    - Ask: "Would a player tell their friend about this?"
  expected_output: >
    Balance review report with:
    - Effects summary
    - Balance concerns
    - Tier appropriateness
    - Player engagement assessment
    - Suggested adjustments
  agent: balance_analyst

# =============================================================================
# DOCUMENTATION TASKS
# =============================================================================

create_planning_doc:
  description: >
    Create a planning/design document for a proposed feature (NOT yet implemented):
    
    Feature: {feature_name}
    Description: {description}
    Related Systems: {related_systems}
    
    PROCESS:
    1. BUILD VERIFICATION REGISTRY FIRST (MANDATORY):
       a. Call list_json_event_ids_tool("Decisions") - save the full list of valid opp_* IDs
       b. Call list_json_event_ids_tool("Events") - save the full list of valid evt_* IDs
       c. For each C# file you plan to reference, call verify_file_exists_tool() BEFORE drafting
       d. Only reference IDs and paths that returned âœ… VERIFIED
    2. Research existing systems using search/read tools
    3. Draft comprehensive planning document in markdown
       - ONLY use file paths and event IDs from your verification registry
       - If you need to reference something not in the registry, verify it first
    4. Use write_planning_doc_tool to save to docs/CrewAI_Plans/
    
    PLANNING DOC RULES:
    - Save to docs/CrewAI_Plans/ using write_planning_doc_tool
    - Set Status: ðŸ“‹ Planning
    - Tool handles versioning automatically (updates vs new versions)
    - DO NOT update INDEX.md Feature Lookup (not implemented yet)
    - DO NOT update AI context docs (no code exists yet)
    - DO reference existing docs as Related Docs
    
    Document Structure:
    1. Title and summary
    2. Problem Statement - What problem does this solve?
    3. Current State - How do existing systems work today?
    4. Proposed Design - Technical approach with data models, methods
    5. Integration Points - Which files/systems are affected?
    6. Implementation Phases - Suggested order of work
    7. Open Questions - Unresolved design decisions
    
    VERIFICATION REQUIREMENTS (CRITICAL - prevents hallucinated references):
    Before including ANY file path or event ID in the document:
    1. Use verify_file_exists_tool("src/Features/SomeFile.cs") for C# file paths
    2. Use list_json_event_ids_tool("Decisions") to verify opportunity IDs exist
    3. Use list_json_event_ids_tool("Events") to verify event IDs exist
    4. NEVER reference files like "EventEffectApplier.cs" without verification
    5. NEVER reference IDs like "opp_some_name" without verifying they exist
    6. If a file doesn't exist, find and use the correct file name
    
    JSON FOLDER PATHS (correct locations):
    - Camp opportunities: ModuleData/Enlisted/Decisions/camp_opportunities.json
    - Events: ModuleData/Enlisted/Events/
    - Order events: ModuleData/Enlisted/Orders/order_events/
    - NOT "Events/" for opportunities - that's WRONG
    
    IMPORTANT: You MUST call write_planning_doc_tool(feature_name="{feature_name}", content="...") to save the document.
  expected_output: >
    Success message from write_planning_doc_tool showing:
    - File path in docs/CrewAI_Plans/
    - Whether it was a new document, minor update, or major version
    - Status: ðŸ“‹ Planning in the document content
  agent: documentation_maintainer

validate_planning_doc:
  description: >
    Validate a planning document for accuracy before finalizing.
    
    You will receive the planning document content from the previous task's output via context.
    
    VALIDATION CHECKS:
    1. File path verification:
       - Extract all C# file paths mentioned (src/Features/*.cs)
       - Use verify_file_exists_tool for EACH path
       - Flag any NOT FOUND paths
    
    2. Event ID verification:
       - Extract all event/opportunity IDs mentioned (opp_*, evt_*, etc.)
       - Use list_json_event_ids_tool("Decisions") for opp_* IDs
       - Use list_json_event_ids_tool("Events") for event IDs
       - Flag any IDs not in the returned lists
    
    3. JSON folder path verification:
       - Camp opportunities should be in Decisions/, NOT Events/
       - Order events should be in Orders/order_events/
       - Flag incorrect folder references
    
    4. Line number verification (if included):
       - Use read_csharp_tool to check if referenced line numbers are approximately correct
       - Flag if method is referenced at line X but actually at line Y (off by >20 lines)
    
    REPORT FORMAT:
    For each issue found, report:
    - âŒ [Type] Description of issue
    - Suggested fix
    
    If all verifications pass:
    - âœ… All file paths verified
    - âœ… All event IDs verified
    - âœ… All folder paths correct
    
    CRITICAL: If ANY errors are found, set status to NEEDS_CORRECTION.
    If all checks pass, set status to VALIDATED.
  expected_output: >
    Validation report with:
    - Status: VALIDATED or NEEDS_CORRECTION
    - List of verification errors found (or "All checks passed")
    - Suggested corrections for each error
    - Overall pass/fail status
  agent: code_analyst

fix_planning_doc:
  description: >
    Fix hallucinations and errors in a planning document.
    
    You will receive the validation report from the previous task via context.
    If the validation status is VALIDATED, simply return "No fixes needed."
    
    If the validation status is NEEDS_CORRECTION:
    1. Read the current planning doc from docs/CrewAI_Plans/{feature_name}.md
    2. For each error in the validation report:
       a. HALLUCINATED FILE PATH: Find the correct file using search_csharp_tool, then replace
       b. HALLUCINATED EVENT ID: Remove the fabricated ID or replace with a real one from list_json_event_ids_tool
       c. WRONG FOLDER PATH: Replace with correct path (Decisions/ for opp_*, Events/ for evt_*)
       d. WRONG LINE NUMBER: Update to correct line or remove line reference
    3. Save the corrected document using write_planning_doc_tool
    
    RULES:
    - Every fix MUST be verified before applying
    - If you can't find a valid replacement, mark with [TODO: needs real reference]
    - Preserve all other content exactly
    - Update "Last Updated" with correction note
  expected_output: >
    Either:
    - "No fixes needed." if validation passed
    - List of corrections made with write_planning_doc_tool success message
  agent: documentation_maintainer

sync_documentation:
  description: >
    Synchronize documentation after IMPLEMENTED code changes. Only run this task
    when actual code/content has been created or modified - NOT for planning docs.
    
    Changed Files: {changed_files}
    Feature Area: {feature_area}
    
    WHEN TO RUN THIS TASK:
    - After C# code is written and builds
    - After JSON content is created and validates
    - After config files are modified
    - NOT after creating planning/design docs (use create_planning_doc instead)
    
    SYNC TASKS:
    1. Identify all docs that reference the changed code
    2. Update feature doc Status field if implementation complete
    3. Update "Last Updated" date with brief change summary
    4. Verify INDEX.md Feature Lookup entries are current
    5. Check if BLUEPRINT.md needs architecture updates
    6. Update CrewAI agent/task configs if tools changed
    7. Ensure cross-references between docs are valid
    
    AI CONTEXT SYNC (CRITICAL - stale context breaks AI assistants):
    If game systems change (tier thresholds, rep ranges, Company Needs, etc.):
    - Update docs_tools.py load_domain_context_tool
    - Update Tools/AGENT-WORKFLOW.md Balance Agent Checklist
    - Update agents.yaml backstories mentioning those values
    - Update validate_content.py if it enforces those values
    If JSON schema rules change:
    - Update Tools/Validation/validate_content.py
    - Update docs/Features/Content/event-system-schemas.md
    - Update VALIDATION_BASELINE.md if expected warnings change
    If CrewAI agents/tools change:
    - Update Tools/CrewAI/README.md
    If Warp workflow changes:
    - Update Tools/AGENT-WORKFLOW.md
    
    INCREMENTAL IMPROVEMENTS (fix on every doc you touch):
    - Ensure standard header format: # Title, **Summary:**, **Status:**, **Last Updated:**, **Related Docs:**
    - Fix filename casing if wrong (SCREAMING-CASE.md â†’ screaming-case.md)
    - Fix broken internal links (../Gameplay/ â†’ ../Campaign/)
    - Move misplaced docs (ANEWFEATURE/reference.md â†’ Reference/)
    - Remove duplicate files (prefer Reference/ or Features/ over ANEWFEATURE/)
    
    IMPORTANT: Small improvements compound. Fix issues in docs you touch.
  expected_output: >
    Documentation sync report with:
    - Docs updated (with change summary)
    - Status field changes
    - INDEX.md updates needed
    - Cross-reference fixes
    - AI context sync updates (CrewAI, Warp, domain context)
    - Incremental improvements made (renames, link fixes, header standardization)
    - Any outstanding doc debt
  agent: documentation_maintainer

audit_documentation:
  description: >
    Audit documentation for accuracy against current codebase:
    
    Scope: {scope}
    
    Checks:
    1. Feature doc Status matches implementation reality
    2. Code examples in docs compile and match actual code
    3. File paths referenced in docs exist
    4. Method signatures in docs match code
    5. Configuration examples match actual config files
    6. INDEX.md entries point to existing docs
    
    Report discrepancies requiring updates.
  expected_output: >
    Documentation audit report with:
    - Stale docs needing updates
    - Broken references
    - Outdated code examples
    - Status field corrections needed
    - Priority ranking (critical/high/medium/low)
  agent: documentation_maintainer

# =============================================================================
# WORKFLOW TASKS (Multi-Agent)
# =============================================================================

full_feature_workflow:
  description: >
    Complete feature development workflow:
    
    Feature: {feature_name}
    Description: {description}
    
    Phases:
    1. Research - Analyze related systems and code
    2. Design - Create technical specification
    3. Review - Validate design before implementation
    4. Implement - Create C# and JSON content
    5. Validate - Run all checks, ensure quality
  expected_output: >
    Feature completion report with:
    - Research findings summary
    - Approved specification
    - Implementation summary
    - Validation results
    - Ready for commit confirmation
  agent: qa_agent
  context:
    - analyze_systems_task
    - design_feature_task
    - implement_csharp_task
    - validate_implementation_task

full_content_workflow:
  description: >
    Complete content creation workflow:
    
    Content Type: {content_type}
    Theme: {theme}
    Requirements: {requirements}
    
    Phases:
    1. Analyze - Review existing content patterns
    2. Create - Write JSON content
    3. Validate - Check schema and style
    4. Balance - Review effects and rewards
    5. Localize - Ensure strings are synced
  expected_output: >
    Content completion report with:
    - Content files created
    - Validation results
    - Balance assessment
    - Localization status
    - Ready for commit confirmation
  agent: qa_agent
  context:
    - analyze_content_structure_task
    - implement_content_task
    - validate_content_file_task
    - review_balance_task
